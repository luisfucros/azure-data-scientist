{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acfb25d1",
   "metadata": {},
   "source": [
    "# Monitoring Data Drift\n",
    "Over time, models can become less effective at predicting accurately due to changing trends in feature data. This phenomenon is known as data drift, and it's important to monitor your machine learning solution to detect it so you can retrain your models if necessary.\n",
    "\n",
    "In this lab, you'll configure data drift monitoring for datasets.\n",
    "\n",
    "## Before you start\n",
    "In addition to the latest version of the azureml-sdk and azureml-widgets packages, you'll need the azureml-datadrift package to run the code in this notebook. Run the cell below to verify that it is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bad733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azureml-datadrift\r\n",
      "Version: 1.41.0\r\n",
      "Summary: Contains functionality for data drift detection for     various datasets used in machine learning.\r\n",
      "Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py\r\n",
      "Author: Microsoft Corp\r\n",
      "Author-email: None\r\n",
      "License: https://aka.ms/azureml-sdk-license\r\n",
      "Location: /anaconda/envs/azureml_py38/lib/python3.8/site-packages\r\n",
      "Requires: azureml-core, pyspark, numpy, scikit-learn, pandas, jsonpickle, lightgbm, azureml-telemetry, msrest, azureml-pipeline-core, matplotlib, scipy, azureml-dataset-runtime\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "!pip show azureml-datadrift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb4952",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "Note: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a66e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to work with aml-workspace\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to work with', ws.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef257b3",
   "metadata": {},
   "source": [
    "## Create a baseline dataset\n",
    "To monitor a dataset for data drift, you must register a baseline dataset (usually the dataset used to train your model) to use as a point of comparison with data collected in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffae80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/diabetes.csv\n",
      "Uploaded ./data/diabetes.csv, 1 files out of an estimated total of 2\n",
      "Uploading ./data/diabetes2.csv\n",
      "Uploaded ./data/diabetes2.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n",
      "Registering baseline dataset...\n",
      "Baseline dataset registered!\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "\n",
    "\n",
    "# Upload the baseline data\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'],\n",
    "                       target_path='diabetes-baseline',\n",
    "                       overwrite=True, \n",
    "                       show_progress=True)\n",
    "\n",
    "# Create and register the baseline dataset\n",
    "print('Registering baseline dataset...')\n",
    "baseline_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-baseline/*.csv'))\n",
    "baseline_data_set = baseline_data_set.register(workspace=ws, \n",
    "                           name='diabetes baseline',\n",
    "                           description='diabetes baseline data',\n",
    "                           tags = {'format':'CSV'},\n",
    "                           create_new_version=True)\n",
    "\n",
    "print('Baseline dataset registered!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc431bf7",
   "metadata": {},
   "source": [
    "## Create a target dataset\n",
    "Over time, you can collect new data with the same features as your baseline training data. To compare this new data to the baseline data, you must define a target dataset that includes the features you want to analyze for data drift as well as a timestamp field that indicates the point in time when the new data was current -this enables you to measure data drift over temporal intervals. The timestamp can either be a field in the dataset itself, or derived from the folder and filename pattern used to store the data. For example, you might store new data in a folder hierarchy that consists of a folder for the year, containing a folder for the month, which in turn contains a folder for the day; or you might just encode the year, month, and day in the file name like this: data_2020-01-29.csv; which is the approach taken in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fab12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating simulated data...\n",
      "Uploading an estimated of 6 files\n",
      "Uploading data/diabetes_2022-04-21.csv\n",
      "Uploaded data/diabetes_2022-04-21.csv, 1 files out of an estimated total of 6\n",
      "Uploading data/diabetes_2022-04-28.csv\n",
      "Uploaded data/diabetes_2022-04-28.csv, 2 files out of an estimated total of 6\n",
      "Uploading data/diabetes_2022-05-05.csv\n",
      "Uploaded data/diabetes_2022-05-05.csv, 3 files out of an estimated total of 6\n",
      "Uploading data/diabetes_2022-05-12.csv\n",
      "Uploaded data/diabetes_2022-05-12.csv, 4 files out of an estimated total of 6\n",
      "Uploading data/diabetes_2022-05-19.csv\n",
      "Uploaded data/diabetes_2022-05-19.csv, 5 files out of an estimated total of 6\n",
      "Uploading data/diabetes_2022-05-26.csv\n",
      "Uploaded data/diabetes_2022-05-26.csv, 6 files out of an estimated total of 6\n",
      "Uploaded 6 files\n",
      "Registering target dataset...\n",
      "Target dataset registered!\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "print('Generating simulated data...')\n",
    "\n",
    "# Load the smaller of the two data files\n",
    "data = pd.read_csv('data/diabetes2.csv')\n",
    "\n",
    "# We'll generate data for the past 6 weeks\n",
    "weeknos = reversed(range(6))\n",
    "\n",
    "file_paths = []\n",
    "for weekno in weeknos:\n",
    "    \n",
    "    # Get the date X weeks ago\n",
    "    data_date = dt.date.today() - dt.timedelta(weeks=weekno)\n",
    "    \n",
    "    # Modify data to ceate some drift\n",
    "    data['Pregnancies'] = data['Pregnancies'] + 1\n",
    "    data['Age'] = round(data['Age'] * 1.2).astype(int)\n",
    "    data['BMI'] = data['BMI'] * 1.1\n",
    "    \n",
    "    # Save the file with the date encoded in the filename\n",
    "    file_path = 'data/diabetes_{}.csv'.format(data_date.strftime(\"%Y-%m-%d\"))\n",
    "    data.to_csv(file_path)\n",
    "    file_paths.append(file_path)\n",
    "\n",
    "# Upload the files\n",
    "path_on_datastore = 'diabetes-target'\n",
    "default_ds.upload_files(files=file_paths,\n",
    "                       target_path=path_on_datastore,\n",
    "                       overwrite=True,\n",
    "                       show_progress=True)\n",
    "\n",
    "# Use the folder partition format to define a dataset with a 'date' timestamp column\n",
    "partition_format = path_on_datastore + '/diabetes_{date:yyyy-MM-dd}.csv'\n",
    "target_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, path_on_datastore + '/*.csv'),\n",
    "                                                       partition_format=partition_format)\n",
    "\n",
    "# Register the target dataset\n",
    "print('Registering target dataset...')\n",
    "target_data_set = target_data_set.with_timestamp_columns('date').register(workspace=ws,\n",
    "                                                                          name='diabetes target',\n",
    "                                                                          description='diabetes target data',\n",
    "                                                                          tags = {'format':'CSV'},\n",
    "                                                                          create_new_version=True)\n",
    "\n",
    "print('Target dataset registered!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f102d6",
   "metadata": {},
   "source": [
    "## Create a data drift monitor\n",
    "Now you're ready to create a data drift monitor for the diabetes data. The data drift monitor will run periodicaly or on-demand to compare the baseline dataset with the target dataset, to which new data will be added over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69c1b0",
   "metadata": {},
   "source": [
    "## Create a compute target\n",
    "To run the data drift monitor, you'll need a compute target. Run the following cell to specify a compute cluster (if it doesn't exist, it will be created).\n",
    "\n",
    "Important: Change your-compute-cluster to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aadf0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress..\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6470c9",
   "metadata": {},
   "source": [
    "## Define the data drift monitor\n",
    "Now you're ready to use a DataDriftDetector class to define the data drift monitor for your data. You can specify the features you want to monitor for data drift, the name of the compute target to be used to run the monitoring process, the frequency at which the data should be compared, the data drift threshold above which an alert should be triggered, and the latency (in hours) to allow for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e675d1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_logger': <_TelemetryLoggerContextAdapter azureml.datadrift._logging._telemetry_logger.azureml.datadrift.datadriftdetector (DEBUG)>, '_workspace': Workspace.create(name='aml-workspace', subscription_id='703026c4-95fb-4a79-b674-b1648c8d0c13', resource_group='aml-resources'), '_frequency': 'Week', '_schedule_start': None, '_schedule_id': None, '_interval': 1, '_state': 'Disabled', '_alert_config': None, '_type': 'DatasetBased', '_id': 'b3bdb88f-67ff-4ed7-9729-27c94b5b5b7a', '_compute_target_name': 'cpu-cluster', '_drift_threshold': 0.3, '_baseline_dataset_id': '0b434613-1e06-4ef2-ac28-8970cdfe99b5', '_target_dataset_id': '498e62ef-ac9e-4daa-8959-51f54cb920ac', '_feature_list': ['Pregnancies', 'Age', 'BMI'], '_latency': 24, '_name': 'mslearn-diabates-drift', '_latest_run_time': None, '_client': <azureml.datadrift._restclient.datadrift_client.DataDriftClient object at 0x7fda5e185ee0>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.datadrift import DataDriftDetector\n",
    "\n",
    "# set up feature list\n",
    "features = ['Pregnancies', 'Age', 'BMI']\n",
    "\n",
    "# set up data drift detector\n",
    "monitor = DataDriftDetector.create_from_datasets(ws, 'mslearn-diabates-drift', baseline_data_set, \n",
    "                                                      target_data_set,\n",
    "                                                      compute_target=cluster_name, \n",
    "                                                      frequency='Week', \n",
    "                                                      feature_list=features, \n",
    "                                                      drift_threshold=.3, \n",
    "                                                      latency=24)\n",
    "monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d879de",
   "metadata": {},
   "source": [
    "## Backfill the data drift monitor\n",
    "You have a baseline dataset and a target dataset that includes simulated weekly data collection for six weeks. You can use this to backfill the monitor so that it can analyze data drift between the original baseline and the target data.\n",
    "\n",
    "Note This may take some time to run, as the compute target must be started to run the backfill analysis. The widget may not always update to show the status, so click the link to observe the experiment status in Azure Machine Learning studio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68024f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a900d81035c4851ac60e510f2d6f0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/mslearn-diabates-drift-Monitor-Runs_1653607428894?wsid=/subscriptions/703026c4-95fb-4a79-b674-b1648c8d0c13/resourcegroups/aml-resources/workspaces/aml-workspace&tid=99e1e721-7184-498e-8aff-b2ad4e53c1c2\", \"run_id\": \"mslearn-diabates-drift-Monitor-Runs_1653607428894\", \"run_properties\": {\"run_id\": \"mslearn-diabates-drift-Monitor-Runs_1653607428894\", \"created_utc\": \"2022-05-26T23:23:53.424037Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlctrain\", \"ContentSnapshotId\": \"bdd321c7-276e-4902-8b73-1cef2df8d481\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-05-26T23:39:56.96183Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=jkJBauxSmg1gcNb%2FBeZUJgcmtc0peTAJkylKdTZUo0I%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A45%3A39Z&se=2022-05-27T07%3A55%3A39Z&sp=r\", \"user_logs/std_log.txt\": \"https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=iYTIp%2BSFFB051Pk9cp1OZf0JIhYMUaLCCVJKXgTRGyY%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A45%3A40Z&se=2022-05-27T07%3A55%3A40Z&sp=r\", \"system_logs/cs_capability/cs-capability.log\": \"https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=MMcOgnqC5yYdfSSd4lCcb56lLcqCNiwP0aFtlot2CJc%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A45%3A40Z&se=2022-05-27T07%3A55%3A40Z&sp=r\", \"system_logs/hosttools_capability/hosttools-capability.log\": \"https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=y8kC6jR6uyu6HcNSPx74H7sIEcyhIMG5SxOzbPrF7fY%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A45%3A40Z&se=2022-05-27T07%3A55%3A40Z&sp=r\", \"system_logs/lifecycler/execution-wrapper.log\": \"https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=fXA6w04RADQiNcsN28%2BpXply5n09CSQtLdfnXVdJGsE%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A45%3A40Z&se=2022-05-27T07%3A55%3A40Z&sp=r\", \"system_logs/lifecycler/lifecycler.log\": \"https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=3uFzeGFKU4Vlr9rAcvseucslwTs1g%2B9cTTvKfylnmpU%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A45%3A40Z&se=2022-05-27T07%3A55%3A40Z&sp=r\"}, \"log_groups\": [[\"user_logs/std_log.txt\", \"system_logs/cs_capability/cs-capability.log\", \"system_logs/hosttools_capability/hosttools-capability.log\", \"system_logs/lifecycler/execution-wrapper.log\", \"system_logs/lifecycler/lifecycler.log\"], [\"azureml-logs/20_image_build_log.txt\"]], \"run_duration\": \"0:16:03\", \"run_number\": \"1653607433\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"start_date\", \"run_id\": \"mslearn-diabates-drift-Monitor-Runs_1653607428894\", \"categories\": [0], \"series\": [{\"data\": [\"2022-04-10\"]}]}, {\"name\": \"end_date\", \"run_id\": \"mslearn-diabates-drift-Monitor-Runs_1653607428894\", \"categories\": [0], \"series\": [{\"data\": [\"2022-05-29\"]}]}, {\"name\": \"frequency\", \"run_id\": \"mslearn-diabates-drift-Monitor-Runs_1653607428894\", \"categories\": [0], \"series\": [{\"data\": [\"Week\"]}]}, {\"name\": \"Datadrift percentage\", \"run_id\": \"mslearn-diabates-drift-Monitor-Runs_1653607428894\", \"categories\": [0], \"series\": [{\"data\": [{\"days_from_start\": [7, 14, 21, 28, 35, 42], \"drift_percentage\": [74.19152901127207, 87.23985219136877, 91.74192122865539, 94.96492628559955, 97.58354951107833, 99.23199438682525]}]}]}], \"run_logs\": \"2022/05/26 23:24:02 Downloading source code...\\r\\n2022/05/26 23:24:03 Finished downloading source code\\r\\n2022/05/26 23:24:03 Creating Docker network: acb_default_network, driver: 'bridge'\\n2022/05/26 23:24:04 Successfully set up Docker network: acb_default_network\\n2022/05/26 23:24:04 Setting up Docker configuration...\\n2022/05/26 23:24:04 Successfully set up Docker configuration\\n2022/05/26 23:24:04 Logging in to registry: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io\\n2022/05/26 23:24:05 Successfully logged into fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io\\n2022/05/26 23:24:05 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2022/05/26 23:24:05 Scanning for dependencies...\\n2022/05/26 23:24:06 Successfully scanned dependencies\\n2022/05/26 23:24:06 Launching container with name: acb_step_0\\r\\nSending build context to Docker daemon  66.56kB\\r\\r\\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04@sha256:c3d39c64396f7e9713da1995e84c551a3ddf25a75173460d53f5af3e28943050\\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04@sha256:c3d39c64396f7e9713da1995e84c551a3ddf25a75173460d53f5af3e28943050: Pulling from azureml/openmpi4.1.0-ubuntu20.04\\nd5fd17ec1767: Pulling fs layer\\n609cb12d79be: Pulling fs layer\\na73a30448a05: Pulling fs layer\\n8fc7787c22de: Pulling fs layer\\nc97611263ed3: Pulling fs layer\\na7934e4e9861: Pulling fs layer\\n59f2464da65a: Pulling fs layer\\n1cfde78a9593: Pulling fs layer\\nc95e1b98b967: Pulling fs layer\\n8fc7787c22de: Waiting\\nc97611263ed3: Waiting\\na7934e4e9861: Waiting\\n59f2464da65a: Waiting\\n1cfde78a9593: Waiting\\nc95e1b98b967: Waiting\\na73a30448a05: Verifying Checksum\\na73a30448a05: Download complete\\nd5fd17ec1767: Verifying Checksum\\nd5fd17ec1767: Download complete\\n8fc7787c22de: Verifying Checksum\\n8fc7787c22de: Download complete\\na7934e4e9861: Verifying Checksum\\na7934e4e9861: Download complete\\nc97611263ed3: Verifying Checksum\\nc97611263ed3: Download complete\\r\\n59f2464da65a: Verifying Checksum\\n59f2464da65a: Download complete\\nc95e1b98b967: Verifying Checksum\\nc95e1b98b967: Download complete\\n1cfde78a9593: Verifying Checksum\\n1cfde78a9593: Download complete\\n609cb12d79be: Verifying Checksum\\n609cb12d79be: Download complete\\nd5fd17ec1767: Pull complete\\n609cb12d79be: Pull complete\\r\\na73a30448a05: Pull complete\\n8fc7787c22de: Pull complete\\nc97611263ed3: Pull complete\\r\\na7934e4e9861: Pull complete\\n59f2464da65a: Pull complete\\n1cfde78a9593: Pull complete\\nc95e1b98b967: Pull complete\\nDigest: sha256:c3d39c64396f7e9713da1995e84c551a3ddf25a75173460d53f5af3e28943050\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04@sha256:c3d39c64396f7e9713da1995e84c551a3ddf25a75173460d53f5af3e28943050\\n ---> 75993396b72f\\nStep 2/21 : USER root\\n ---> Running in e31861b8e423\\nRemoving intermediate container e31861b8e423\\n ---> af039b2ae774\\nStep 3/21 : RUN mkdir -p $HOME/.cache\\r\\n ---> Running in c54dc2eb86e5\\nRemoving intermediate container c54dc2eb86e5\\n ---> 5907ec1277e0\\nStep 4/21 : WORKDIR /\\n ---> Running in 1743c7780b73\\nRemoving intermediate container 1743c7780b73\\n ---> a496eae2742e\\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\r\\n ---> b118260fc2f7\\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in fcf95189be4f\\nRemoving intermediate container fcf95189be4f\\n ---> 225eb4334b2a\\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\r\\n ---> 9487ccdddab5\\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \\\"$HOME/.cache/pip\\\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \\\"$CONDA_ROOT_DIR/pkgs\\\" && find \\\"$CONDA_ROOT_DIR\\\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in f131f01477d8\\nWarning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\\r\\nCollecting package metadata (repodata.json): ...working... done\\r\\nSolving environment: ...working... done\\r\\n\\nDownloading and Extracting Packages\\n\\rimportlib_metadata-4 | 11 KB     |            |   0% \\rimportlib_metadata-4 | 11 KB     | ########## | 100% \\n\\rgflags-2.2.2         | 126 KB    |            |   0% \\rgflags-2.2.2         | 126 KB    | ########## | 100% \\n\\rbzip2-1.0.8          | 78 KB     |            |   0% \\rbzip2-1.0.8          | 78 KB     | ########## | 100% \\n\\rdouble-conversion-3. | 235 KB    |            |   0% \\rdouble-conversion-3. | 235 KB    | ########## | 100% \\n\\rmkl_fft-1.3.0        | 170 KB    |            |   0% \\rmkl_fft-1.3.0        | 170 KB    | ########## | 100% \\n\\rpandas-1.1.5         | 8.2 MB    |            |   0% \\rpandas-1.1.5         | 8.2 MB    | ########## | 100% \\rpandas-1.1.5         | 8.2 MB    | ########## | 100% \\n\\rpyarrow-0.13.0       | 1.8 MB    |            |   0% \\rpyarrow-0.13.0       | 1.8 MB    | ########## | 100% \\n\\rscikit-learn-0.24.2  | 5.2 MB    |            |   0% \\rscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \\rscikit-learn-0.24.2  | 5.2 MB    | ########## | 100% \\n\\rzipp-3.6.0           | 17 KB     |            |   0% \\rzipp-3.6.0           | 17 KB     | ########## | 100% \\n\\rsqlite-3.23.1        | 808 KB    |            |   0% \\rsqlite-3.23.1        | 808 KB    | ########## | 100% \\n\\rthreadpoolctl-2.2.0  | 16 KB     |            |   0% \\rthreadpoolctl-2.2.0  | 16 KB     | ########## | 100% \\n\\rlz4-c-1.8.1.2        | 130 KB    |            |   0% \\rlz4-c-1.8.1.2        | 130 KB    | ########## | 100% \\n\\rsetuptools-58.0.4    | 788 KB    |            |   0% \\rsetuptools-58.0.4    | 788 KB    | ########## | 100% \\n\\rarrow-cpp-0.13.0     | 2.9 MB    |            |   0% \\rarrow-cpp-0.13.0     | 2.9 MB    | ########## | 100% \\rarrow-cpp-0.13.0     | 2.9 MB    | ########## | 100% \\n\\rblas-1.0             | 6 KB      |            |   0% \\rblas-1.0             | 6 KB      | ########## | 100% \\n\\rjsonpickle-2.0.0     | 34 KB     |            |   0% \\rjsonpickle-2.0.0     | 34 KB     | ########## | 100% \\n\\rlibboost-1.67.0      | 13.0 MB   |            |   0% \\rlibboost-1.67.0      | 13.0 MB   | #######9   |  79% \\rlibboost-1.67.0      | 13.0 MB   | ########## | 100% \\r\\n\\r_libgcc_mutex-0.1    | 3 KB      |            |   0% \\r_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \\n\\rmkl_random-1.1.1     | 327 KB    |            |   0% \\rmkl_random-1.1.1     | 327 KB    | ########## | 100% \\n\\rsnappy-1.1.9         | 636 KB    |            |   0% \\rsnappy-1.1.9         | 636 KB    | ########## | 100% \\n\\rmkl-2020.2           | 138.3 MB  |            |   0% \\rmkl-2020.2           | 138.3 MB  | 9          |  10% \\rmkl-2020.2           | 138.3 MB  | #9         |  19% \\rmkl-2020.2           | 138.3 MB  | ##9        |  30% \\rmkl-2020.2           | 138.3 MB  | ####       |  40% \\rmkl-2020.2           | 138.3 MB  | #####      |  51% \\rmkl-2020.2           | 138.3 MB  | ######1    |  61% \\rmkl-2020.2           | 138.3 MB  | #######2   |  73% \\rmkl-2020.2           | 138.3 MB  | ########3  |  83% \\rmkl-2020.2           | 138.3 MB  | #########3 |  94% \\rmkl-2020.2           | 138.3 MB  | ########## | 100% \\r\\n\\rtyping_extensions-4. | 28 KB     |            |   0% \\rtyping_extensions-4. | 28 KB     | ########## | 100% \\n\\rlibgfortran4-7.5.0   | 995 KB    |            |   0% \\rlibgfortran4-7.5.0   | 995 KB    | ########## | 100% \\n\\rbrotli-1.0.9         | 375 KB    |            |   0% \\rbrotli-1.0.9         | 375 KB    | ########## | 100% \\n\\ricu-58.2             | 10.5 MB   |            |   0% \\ricu-58.2             | 10.5 MB   | ########5  |  86% \\ricu-58.2             | 10.5 MB   | ########## | 100% \\n\\rlibprotobuf-3.6.0    | 2.5 MB    |            |   0% \\rlibprotobuf-3.6.0    | 2.5 MB    | ########## | 100% \\rlibprotobuf-3.6.0    | 2.5 MB    | ########## | 100% \\n\\rjoblib-1.0.1         | 208 KB    |            |   0% \\rjoblib-1.0.1         | 208 KB    | ########## | 100% \\n\\rnumpy-1.19.2         | 22 KB     |            |   0% \\rnumpy-1.19.2         | 22 KB     | ########## | 100% \\n\\rxz-5.2.5             | 339 KB    |            |   0% \\rxz-5.2.5             | 339 KB    | ########## | 100% \\n\\rnumpy-base-1.19.2    | 4.1 MB    |            |   0% \\rnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \\rnumpy-base-1.19.2    | 4.1 MB    | ########## | 100% \\n\\rreadline-7.0         | 848 KB    |            |   0% \\rreadline-7.0         | 848 KB    | ########## | 100% \\n\\rlibgcc-ng-11.2.0     | 5.3 MB    |            |   0% \\rlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \\rlibgcc-ng-11.2.0     | 5.3 MB    | ########## | 100% \\n\\r_openmp_mutex-5.1    | 21 KB     |            |   0% \\r_openmp_mutex-5.1    | 21 KB     | ########## | 100% \\n\\rpython-3.6.2         | 23.6 MB   |            |   0% \\rpython-3.6.2         | 23.6 MB   | ####6      |  46% \\rpython-3.6.2         | 23.6 MB   | #########1 |  91% \\rpython-3.6.2         | 23.6 MB   | ########## | 100% \\n\\rzstd-1.3.7           | 401 KB    |            |   0% \\rzstd-1.3.7           | 401 KB    | ########## | 100% \\n\\rre2-2022.04.01       | 210 KB    |            |   0% \\rre2-2022.04.01       | 210 KB    | ########## | 100% \\n\\rsix-1.16.0           | 18 KB     |            |   0% \\rsix-1.16.0           | 18 KB     | ########## | 100% \\n\\rncurses-6.0          | 781 KB    |            |   0% \\rncurses-6.0          | 781 KB    | ########## | 100% \\rncurses-6.0          | 781 KB    | ########## | 100% \\n\\rlibedit-3.1          | 151 KB    |            |   0% \\rlibedit-3.1          | 151 KB    | ########## | 100% \\n\\rpytz-2021.3          | 171 KB    |            |   0% \\rpytz-2021.3          | 171 KB    | ########## | 100% \\r\\n\\rthrift-cpp-0.11.0    | 1.9 MB    |            |   0% \\rthrift-cpp-0.11.0    | 1.9 MB    | ########## | 100% \\n\\rpip-21.2.2           | 1.8 MB    |            |   0% \\rpip-21.2.2           | 1.8 MB    | ########## | 100% \\rpip-21.2.2           | 1.8 MB    | ########## | 100% \\n\\ropenssl-1.0.2u       | 2.2 MB    |            |   0% \\ropenssl-1.0.2u       | 2.2 MB    | ########## | 100% \\n\\rlibgfortran-ng-7.5.0 | 22 KB     |            |   0% \\rlibgfortran-ng-7.5.0 | 22 KB     | ########## | 100% \\n\\rzlib-1.2.12          | 106 KB    |            |   0% \\rzlib-1.2.12          | 106 KB    | ########## | 100% \\n\\rglog-0.5.0           | 101 KB    |            |   0% \\rglog-0.5.0           | 101 KB    | ########## | 100% \\n\\rcertifi-2021.5.30    | 139 KB    |            |   0% \\rcertifi-2021.5.30    | 139 KB    | ########## | 100% \\n\\rwheel-0.37.1         | 33 KB     |            |   0% \\rwheel-0.37.1         | 33 KB     | ########## | 100% \\n\\rlibffi-3.2.1         | 48 KB     |            |   0% \\rlibffi-3.2.1         | 48 KB     | ########## | 100% \\n\\rscipy-1.5.2          | 14.4 MB   |            |   0% \\rscipy-1.5.2          | 14.4 MB   | #######7   |  77% \\rscipy-1.5.2          | 14.4 MB   | ########## | 100% \\n\\rlibgomp-11.2.0       | 473 KB    |            |   0% \\rlibgomp-11.2.0       | 473 KB    | ########## | 100% \\n\\rmkl-service-2.3.0    | 52 KB     |            |   0% \\rmkl-service-2.3.0    | 52 KB     | ########## | 100% \\n\\rpython-dateutil-2.8. | 233 KB    |            |   0% \\rpython-dateutil-2.8. | 233 KB    | ########## | 100% \\n\\rtk-8.6.11            | 3.0 MB    |            |   0% \\rtk-8.6.11            | 3.0 MB    | ########## | 100% \\rtk-8.6.11            | 3.0 MB    | ########## | 100% \\n\\rlibstdcxx-ng-11.2.0  | 4.7 MB    |            |   0% \\rlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \\rlibstdcxx-ng-11.2.0  | 4.7 MB    | ########## | 100% \\n\\rboost-cpp-1.67.0     | 11 KB     |            |   0% \\rboost-cpp-1.67.0     | 11 KB     | ########## | 100% \\n\\rca-certificates-2022 | 124 KB    |            |   0% \\rca-certificates-2022 | 124 KB    | ########## | 100% \\n\\rlightgbm-2.3.0       | 936 KB    |            |   0% \\rlightgbm-2.3.0       | 936 KB    | ########## | 100% \\n\\rintel-openmp-2022.0. | 4.2 MB    |            |   0% \\rintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \\rintel-openmp-2022.0. | 4.2 MB    | ########## | 100% \\n\\rpsutil-5.8.0         | 329 KB    |            |   0% \\rpsutil-5.8.0         | 329 KB    | ########## | 100% \\n\\rimportlib-metadata-4 | 38 KB     |            |   0% \\rimportlib-metadata-4 | 38 KB     | ########## | 100% \\n\\rlibevent-2.1.8       | 912 KB    |            |   0% \\rlibevent-2.1.8       | 912 KB    | ########## | 100% \\nPreparing transaction: ...working... done\\r\\nVerifying transaction: ...working... done\\r\\nExecuting transaction: ...working... \\n\\n    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.\\n    More details are available here: https://intel.github.io/scikit-learn-intelex\\n\\n    For example:\\n\\n        $ conda install scikit-learn-intelex\\n        $ python -m sklearnex my_application.py\\n\\n    \\n\\ndone\\r\\nInstalling pip dependencies: ...working... \\r\\nRan pip subprocess with arguments:\\n['/azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt']\\nPip subprocess output:\\nCollecting azureml-defaults==1.41.0\\n  Downloading azureml_defaults-1.41.0-py3-none-any.whl (3.0 kB)\\nCollecting azureml-datadrift==1.41.0\\n  Downloading azureml_datadrift-1.41.0-py3-none-any.whl (99 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting azureml-inference-server-http~=0.4.1\\n  Downloading azureml_inference_server_http-0.4.13-py3-none-any.whl (39 kB)\\nCollecting azureml-core~=1.41.0\\n  Downloading azureml_core-1.41.0.post3-py3-none-any.whl (2.7 MB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting azureml-dataset-runtime[fuse]~=1.41.0\\n  Downloading azureml_dataset_runtime-1.41.0-py3-none-any.whl (3.5 kB)\\nCollecting msrest>=0.5.1\\n  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\\nRequirement already satisfied: scikit-learn in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (0.24.2)\\nCollecting matplotlib<=3.2.1,>=3.0.2\\n  Downloading matplotlib-3.2.1-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\\nRequirement already satisfied: jsonpickle in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (2.0.0)\\nRequirement already satisfied: pandas in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (1.1.5)\\nCollecting azureml-telemetry~=1.41.0\\n  Downloading azureml_telemetry-1.41.0-py3-none-any.whl (31 kB)\\nCollecting azureml-pipeline-core~=1.41.0\\n  Downloading azureml_pipeline_core-1.41.0-py3-none-any.whl (313 kB)\\nRequirement already satisfied: scipy>=1.0.0 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (1.5.2)\\nRequirement already satisfied: lightgbm in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (2.3.0)\\nRequirement already satisfied: numpy in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (1.19.2)\\nCollecting pyspark\\n  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\\nCollecting PyJWT<3.0.0\\n  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\\nCollecting jmespath<1.0.0\\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\\nCollecting azure-mgmt-resource<21.0.0,>=15.0.0\\n  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\\nCollecting msrestazure<=0.6.4,>=0.4.33\\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\\nCollecting packaging<22.0,>=20.0\\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\\nCollecting pyopenssl<23.0.0\\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\\nCollecting paramiko<3.0.0,>=2.0.8\\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\\nCollecting azure-mgmt-authorization<3,>=0.40.0\\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\\nCollecting azure-mgmt-containerregistry<10,>=8.2.0\\n  Downloading azure_mgmt_containerregistry-9.1.0-py3-none-any.whl (1.1 MB)\\nCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\\n  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\\nCollecting pathspec<1.0.0\\n  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\\nCollecting pkginfo\\n  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\\nCollecting azure-mgmt-storage<20.0.0,>=16.0.0\\n  Downloading azure_mgmt_storage-19.1.0-py3-none-any.whl (1.8 MB)\\nCollecting urllib3<=1.26.7,>=1.23\\n  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\\nCollecting humanfriendly<11.0,>=4.7\\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\\nCollecting knack~=0.9.0\\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\\nCollecting docker<6.0.0\\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\\nCollecting msal-extensions<0.4,>=0.3.0\\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\\nCollecting ndg-httpsclient<=0.5.1\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting azure-graphrbac<1.0.0,>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting contextlib2<22.0.0\\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\\nCollecting requests[socks]<3.0.0,>=2.19.1\\n  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\\nCollecting msal<2.0.0,>=1.15.0\\n  Downloading msal-1.17.0-py2.py3-none-any.whl (79 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\\n  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-core~=1.41.0->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (2.8.2)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting azure-core<=1.22.1\\n  Downloading azure_core-1.22.1-py3-none-any.whl (178 kB)\\nCollecting argcomplete<3\\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\\nCollecting SecretStorage<4.0.0\\n  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\\nRequirement already satisfied: pytz in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azureml-core~=1.41.0->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (2021.3)\\nCollecting azure-common<2.0.0,>=1.1.12\\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\\nCollecting adal<=1.2.7,>=1.2.0\\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\\nRequirement already satisfied: importlib-metadata<5,>=0.23 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from argcomplete<3->azureml-core~=1.41.0->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (4.8.1)\\nRequirement already satisfied: six>=1.11.0 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from azure-core<=1.22.1->azureml-core~=1.41.0->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (1.16.0)\\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\\n  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\\nCollecting pyarrow<4.0.0,>=0.17.0\\n  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\\nCollecting azureml-dataprep<3.2.0a,>=3.1.0a\\n  Downloading azureml_dataprep-3.1.3-py3-none-any.whl (38.6 MB)\\nCollecting fusepy<4.0.0,>=3.0.1\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting azure-identity==1.7.0\\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\\nCollecting azureml-dataprep-rslex~=2.5.0dev0\\n  Downloading azureml_dataprep_rslex-2.5.4-cp36-cp36m-manylinux2010_x86_64.whl (15.4 MB)\\nCollecting cloudpickle<3.0.0,>=1.1.0\\n  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\\nCollecting dotnetcore2<3.0.0,>=2.1.14\\n  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\\n  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\\nCollecting click<8.0,>=5.1\\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\\nCollecting Werkzeug<2.0,>=0.15\\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\\nCollecting applicationinsights>=0.11.7\\n  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\\nCollecting gunicorn==20.1.0\\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\\nCollecting inference-schema==1.3.0\\n  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nCollecting opencensus-ext-azure~=1.1.0\\n  Downloading opencensus_ext_azure-1.1.4-py2.py3-none-any.whl (40 kB)\\nCollecting Jinja2<3.1,>=2.10.1\\n  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\\nCollecting itsdangerous<2.0,>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nRequirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (58.0.4)\\nCollecting wrapt<=1.12.1,>=1.11.1\\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\\nCollecting cffi>=1.12\\n  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\\nRequirement already satisfied: typing-extensions>=3.6.4 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from importlib-metadata<5,>=0.23->argcomplete<3->azureml-core~=1.41.0->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (4.1.1)\\nRequirement already satisfied: zipp>=0.5 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from importlib-metadata<5,>=0.23->argcomplete<3->azureml-core~=1.41.0->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (3.6.0)\\nCollecting MarkupSafe>=2.0\\n  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\\nCollecting pyyaml\\n  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\\nCollecting tabulate\\n  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\\nCollecting pygments\\n  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\\nCollecting kiwisolver>=1.0.1\\n  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\\n  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\\nCollecting cycler>=0.10\\n  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\\nCollecting portalocker<3,>=1.0\\n  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (2021.5.30)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting opencensus<1.0.0,>=0.8.0\\n  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\\nRequirement already satisfied: psutil>=5.6.3 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 1)) (5.8.0)\\nCollecting opencensus-context>=0.1.2\\n  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\\nCollecting google-api-core<3.0.0,>=1.0.0\\n  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\\nCollecting google-auth<3.0dev,>=1.25.0\\n  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\\nCollecting protobuf<4.0.0dev,>=3.15.0\\n  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\\n  Downloading googleapis_common_protos-1.56.2-py2.py3-none-any.whl (211 kB)\\nCollecting rsa<5,>=3.1.4\\n  Downloading rsa-4.8-py3-none-any.whl (39 kB)\\nCollecting pyasn1-modules>=0.2.1\\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\\nCollecting cachetools<6.0,>=2.0.0\\n  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\\nCollecting contextvars\\n  Downloading contextvars-2.4.tar.gz (9.6 kB)\\nCollecting bcrypt>=3.1.3\\n  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\\nCollecting pynacl>=1.0.1\\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\\nCollecting idna<4,>=2.5\\n  Downloading idna-3.3-py3-none-any.whl (61 kB)\\nCollecting charset-normalizer~=2.0.0\\n  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\\nCollecting PySocks!=1.5.7,>=1.5.6\\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\\nCollecting jeepney>=0.6\\n  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting immutables>=0.9\\n  Downloading immutables-0.18-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (115 kB)\\nCollecting py4j==0.10.9.3\\n  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\\nRequirement already satisfied: threadpoolctl>=2.0.0 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from scikit-learn->azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (2.2.0)\\nRequirement already satisfied: joblib>=0.11 in /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib/python3.6/site-packages (from scikit-learn->azureml-datadrift==1.41.0->-r /azureml-environment-setup/condaenv.wx9tfn3y.requirements.txt (line 2)) (1.0.1)\\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt, contextvars, pyspark\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=cafa088379c518bf14c4e94eb65b05d4f778bf2b0c123bbe11120db56cac5d4d\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status 'done'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=ec18ba4aed6d8c7300f342abdca40e69b674b01b364ae57fdd9800f26c57d66c\\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\\n  Building wheel for wrapt (setup.py): started\\n  Building wheel for wrapt (setup.py): finished with status 'done'\\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=76169 sha256=96087ce11e28a9f754c1debd8f6bacdafb9f06178eadc524012905e7e58e7184\\n  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\\n  Building wheel for contextvars (setup.py): started\\n  Building wheel for contextvars (setup.py): finished with status 'done'\\n  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=9aba7ba71a873f72b45e4ce59a1f99d921211b92f2c73889685ba50423adbcb2\\n  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\\n  Building wheel for pyspark (setup.py): started\\n  Building wheel for pyspark (setup.py): finished with status 'done'\\n  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=3fcf1098b646e1394878155d66e57b985afb53097f73392a26ad08fbf5e4c2d7\\n  Stored in directory: /root/.cache/pip/wheels/bc/fa/63/f112e9bf64fa59f349f9d37b48b70911435dc532ff49cffddc\\r\\nSucce\\u001b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.11.0\\n  latest version: 4.13.0\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\u001b[0mssfully built json-logging-py fusepy wrapt contextvars pyspark\\nInstalling collected packages: pycparser, cffi, urllib3, PyJWT, idna, cryptography, charset-normalizer, requests, pyasn1, oauthlib, rsa, requests-oauthlib, pyasn1-modules, protobuf, portalocker, msal, isodate, immutables, cachetools, msrest, msal-extensions, googleapis-common-protos, google-auth, distro, contextvars, azure-core, adal, websocket-client, tabulate, pyyaml, PySocks, pyparsing, pyopenssl, pynacl, pygments, opencensus-context, msrestazure, MarkupSafe, jmespath, jeepney, google-api-core, dotnetcore2, cloudpickle, bcrypt, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-mgmt-core, azure-identity, azure-common, argcomplete, wrapt, Werkzeug, SecretStorage, pyarrow, pkginfo, pathspec, paramiko, packaging, opencensus, ndg-httpsclient, knack, Jinja2, itsdangerous, humanfriendly, docker, contextlib2, click, backports.tempfile, azureml-dataprep, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, py4j, opencensus-ext-azure, kiwisolver, inference-schema, gunicorn, fusepy, flask, cycler, azureml-dataset-runtime, azureml-core, applicationinsights, pyspark, matplotlib, json-logging-py, configparser, azureml-telemetry, azureml-pipeline-core, azureml-inference-server-http, azureml-defaults, azureml-datadrift\\n  Attempting uninstall: pyarrow\\n    Found existing installation: pyarrow 0.13.0\\n    Uninstalling pyarrow-0.13.0:\\n      Successfully uninstalled pyarrow-0.13.0\\nSuccessfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.2 Werkzeug-1.0.1 adal-1.2.7 applicationinsights-0.11.10 argcomplete-2.0.0 azure-common-1.1.28 azure-core-1.22.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-9.1.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.1.0 azureml-core-1.41.0.post3 azureml-datadrift-1.41.0 azureml-dataprep-3.1.3 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.5.4 azureml-dataset-runtime-1.41.0 azureml-defaults-1.41.0 azureml-inference-server-http-0.4.13 azureml-pipeline-core-1.41.0 azureml-telemetry-1.41.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.2 cachetools-4.2.4 cffi-1.15.0 charset-normalizer-2.0.12 click-7.1.2 cloudpickle-2.1.0 configparser-3.7.4 contextlib2-21.6.0 contextvars-2.4 cryptography-36.0.2 cycler-0.11.0 distro-1.7.0 docker-5.0.3 dotnetcore2-2.1.23 flask-1.0.3 fusepy-3.0.1 google-api-core-2.8.1 google-auth-2.6.6 googleapis-common-protos-1.56.2 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 immutables-0.18 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 kiwisolver-1.3.1 knack-0.9.0 matplotlib-3.2.1 msal-1.17.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 opencensus-0.9.0 opencensus-context-0.1.2 opencensus-ext-azure-1.1.4 packaging-21.3 paramiko-2.11.0 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.4.0 protobuf-3.19.4 py4j-0.10.9.3 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.12.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.7 pyspark-3.2.1 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tabulate-0.8.9 urllib3-1.26.7 websocket-client-1.3.1 wrapt-1.12.1\\n\\ndone\\n#\\n# To activate this environment, use\\n#\\n#     $ conda activate /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192\\n#\\n# To deactivate an active environment, use\\n#\\n#     $ conda deactivate\\n\\nWARNING: /root/.conda/pkgs does not exist\\n\\r\\nRemoving intermediate container f131f01477d8\\n ---> 977b77c4dbdc\\nStep 9/21 : ENV PATH /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/bin:$PATH\\r\\n ---> Running in 7146a26fa6c7\\nRemoving intermediate container 7146a26fa6c7\\n ---> b5985808fc59\\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\\r\\n ---> 881e860af387\\nStep 11/21 : RUN echo \\\"Copying environment context\\\"\\r\\n ---> Running in ad11d3f778e3\\nCopying environment context\\nRemoving intermediate container ad11d3f778e3\\n ---> 060fa7fcedce\\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\\r\\n ---> 8a0a2e2d27f7\\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192\\r\\n ---> Running in 1944cd1cf878\\nReport materialized dependencies for the environment\\nReading environment context\\nExporting conda environment\\nSending request with materialized conda environment details\\nSuccessfully sent materialized environment details\\r\\nRemoving intermediate container 1944cd1cf878\\n ---> ee379b35300f\\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192\\r\\n ---> Running in b09e8299ef72\\nRemoving intermediate container b09e8299ef72\\n ---> a0ba58a9dcfe\\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192/lib:$LD_LIBRARY_PATH\\r\\n ---> Running in d3b8e29ccff8\\nRemoving intermediate container d3b8e29ccff8\\n ---> 18ccf0282b69\\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_dfd712e7b19c5840fa970e0d48de2192 CONDA_PREFIX=/azureml-envs/azureml_dfd712e7b19c5840fa970e0d48de2192\\r\\n ---> Running in debb717bca7b\\nRemoving intermediate container debb717bca7b\\n ---> f01dcf37e79d\\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\r\\n ---> c79ec4610192\\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\\r\\n ---> Running in bb4986f921e4\\nRemoving intermediate container bb4986f921e4\\n ---> 4d0e41c84ae2\\nStep 19/21 : RUN rm -rf azureml-environment-setup\\r\\n ---> Running in 5f7f92d800d0\\nRemoving intermediate container 5f7f92d800d0\\n ---> f2dc96bd9941\\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\\r\\n ---> Running in 5f919f0fd669\\nRemoving intermediate container 5f919f0fd669\\n ---> 3af367910483\\nStep 21/21 : CMD [\\\"bash\\\"]\\r\\n ---> Running in 7bb2b1e6f317\\nRemoving intermediate container 7bb2b1e6f317\\r\\n ---> 12a958bb5729\\nSuccessfully built 12a958bb5729\\nSuccessfully tagged fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8:latest\\nSuccessfully tagged fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8:1\\n2022/05/26 23:26:56 Successfully executed container: acb_step_0\\n2022/05/26 23:26:56 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2022/05/26 23:26:56 Pushing image: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8:1, attempt 1\\nThe push refers to repository [fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8]\\n58e80dc07b71: Preparing\\n1fb06a904626: Preparing\\n200f312f22b2: Preparing\\ndcc9ee3ff11d: Preparing\\nc3698ae780b0: Preparing\\n0a997e36757f: Preparing\\nb79289311e34: Preparing\\n1658416da41f: Preparing\\n9be40b8522c2: Preparing\\n988105b000dd: Preparing\\na009d5014665: Preparing\\nc728520d5d46: Preparing\\na50fff8d387e: Preparing\\n848ff9fcfe17: Preparing\\n44a81578147f: Preparing\\n06aad7bf3ec5: Preparing\\nbbe63fdd5427: Preparing\\n403113671ffd: Preparing\\nbf8cedc62fb3: Preparing\\n0a997e36757f: Waiting\\nb79289311e34: Waiting\\n1658416da41f: Waiting\\n9be40b8522c2: Waiting\\n988105b000dd: Waiting\\na009d5014665: Waiting\\nc728520d5d46: Waiting\\na50fff8d387e: Waiting\\n848ff9fcfe17: Waiting\\n44a81578147f: Waiting\\n06aad7bf3ec5: Waiting\\nbbe63fdd5427: Waiting\\n403113671ffd: Waiting\\nbf8cedc62fb3: Waiting\\ndcc9ee3ff11d: Pushed\\n58e80dc07b71: Pushed\\nc3698ae780b0: Pushed\\r\\n1fb06a904626: Pushed\\n200f312f22b2: Pushed\\nb79289311e34: Pushed\\n1658416da41f: Pushed\\n988105b000dd: Pushed\\n9be40b8522c2: Pushed\\na009d5014665: Pushed\\nc728520d5d46: Pushed\\r\\n848ff9fcfe17: Pushed\\r\\na50fff8d387e: Pushed\\n06aad7bf3ec5: Pushed\\nbf8cedc62fb3: Pushed\\r\\nbbe63fdd5427: Pushed\\n44a81578147f: Pushed\\r\\n403113671ffd: Pushed\\r\\n0a997e36757f: Pushed\\r\\n1: digest: sha256:beac70fc7120c9f12af8a06f54052447bcbbb368d77e70ed0a9f086868d55a42 size: 4306\\r\\n2022/05/26 23:29:02 Successfully pushed image: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8:1\\n2022/05/26 23:29:02 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2022/05/26 23:29:02 Pushing image: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8:latest, attempt 1\\nThe push refers to repository [fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8]\\n58e80dc07b71: Preparing\\n1fb06a904626: Preparing\\n200f312f22b2: Preparing\\ndcc9ee3ff11d: Preparing\\nc3698ae780b0: Preparing\\n0a997e36757f: Preparing\\nb79289311e34: Preparing\\n1658416da41f: Preparing\\n9be40b8522c2: Preparing\\n988105b000dd: Preparing\\na009d5014665: Preparing\\nc728520d5d46: Preparing\\na50fff8d387e: Preparing\\n848ff9fcfe17: Preparing\\n44a81578147f: Preparing\\n06aad7bf3ec5: Preparing\\nbbe63fdd5427: Preparing\\n403113671ffd: Preparing\\nbf8cedc62fb3: Preparing\\nc728520d5d46: Waiting\\na50fff8d387e: Waiting\\n0a997e36757f: Waiting\\n848ff9fcfe17: Waiting\\n44a81578147f: Waiting\\nb79289311e34: Waiting\\n06aad7bf3ec5: Waiting\\n1658416da41f: Waiting\\nbbe63fdd5427: Waiting\\n9be40b8522c2: Waiting\\n403113671ffd: Waiting\\n988105b000dd: Waiting\\na009d5014665: Waiting\\nbf8cedc62fb3: Waiting\\n58e80dc07b71: Layer already exists\\n200f312f22b2: Layer already exists\\n1fb06a904626: Layer already exists\\ndcc9ee3ff11d: Layer already exists\\nc3698ae780b0: Layer already exists\\n9be40b8522c2: Layer already exists\\n1658416da41f: Layer already exists\\n988105b000dd: Layer already exists\\n0a997e36757f: Layer already exists\\nb79289311e34: Layer already exists\\na009d5014665: Layer already exists\\na50fff8d387e: Layer already exists\\n848ff9fcfe17: Layer already exists\\nc728520d5d46: Layer already exists\\n44a81578147f: Layer already exists\\nbbe63fdd5427: Layer already exists\\n06aad7bf3ec5: Layer already exists\\nbf8cedc62fb3: Layer already exists\\n403113671ffd: Layer already exists\\nlatest: digest: sha256:beac70fc7120c9f12af8a06f54052447bcbbb368d77e70ed0a9f086868d55a42 size: 4306\\n2022/05/26 23:29:03 Successfully pushed image: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io/azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8:latest\\n2022/05/26 23:29:03 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 170.573288)\\n2022/05/26 23:29:03 Populating digests for step ID: acb_step_0...\\n2022/05/26 23:29:04 Successfully populated digests for step ID: acb_step_0\\n2022/05/26 23:29:04 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 126.103202)\\n2022/05/26 23:29:04 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.459669)\\r\\n2022/05/26 23:29:04 The following dependencies were found:\\n2022/05/26 23:29:04 \\n- image:\\n    registry: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io\\n    repository: azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8\\n    tag: latest\\n    digest: sha256:beac70fc7120c9f12af8a06f54052447bcbbb368d77e70ed0a9f086868d55a42\\n  runtime-dependency:\\n    registry: mcr.microsoft.com\\n    repository: azureml/openmpi4.1.0-ubuntu20.04\\n    digest: sha256:c3d39c64396f7e9713da1995e84c551a3ddf25a75173460d53f5af3e28943050\\n  git: {}\\n- image:\\n    registry: fe90126fc0254d4e9994e4ccdbe0ed18.azurecr.io\\n    repository: azureml/azureml_f66e228ec8dbab030ac250f09b1a3ec8\\n    tag: \\\"1\\\"\\n    digest: sha256:beac70fc7120c9f12af8a06f54052447bcbbb368d77e70ed0a9f086868d55a42\\n  runtime-dependency:\\n    registry: mcr.microsoft.com\\n    repository: azureml/openmpi4.1.0-ubuntu20.04\\n    digest: sha256:c3d39c64396f7e9713da1995e84c551a3ddf25a75173460d53f5af3e28943050\\n  git: {}\\n\\n\\r\\nRun ID: ca1 was successful after 5m3s\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.41.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'mslearn-diabates-drift-Monitor-Runs_1653607428894',\n",
       " 'target': 'cpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-05-26T23:36:23.557224Z',\n",
       " 'endTimeUtc': '2022-05-26T23:39:56.96183Z',\n",
       " 'services': {},\n",
       " 'warnings': [{'source': 'datadrift',\n",
       "   'message': 'target dataset id:498e62ef-ac9e-4daa-8959-51f54cb920ac do not contain sufficient amount of data after timestamp filteringMinimum needed: 50 rows.Skipping calculation for time slice 2022-04-10 00:00:00 to 2022-04-17 00:00:00.'}],\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n",
       "  'ContentSnapshotId': 'bdd321c7-276e-4902-8b73-1cef2df8d481',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '0b434613-1e06-4ef2-ac28-8970cdfe99b5'}, 'consumptionDetails': {'type': 'Reference'}}, {'dataset': {'id': '498e62ef-ac9e-4daa-8959-51f54cb920ac'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': '_generate_script_datasets.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--baseline_dataset_id',\n",
       "   '0b434613-1e06-4ef2-ac28-8970cdfe99b5',\n",
       "   '--target_dataset_id',\n",
       "   '498e62ef-ac9e-4daa-8959-51f54cb920ac',\n",
       "   '--workspace_name',\n",
       "   'aml-workspace',\n",
       "   '--workspace_location',\n",
       "   'eastus',\n",
       "   '--instrumentation_key',\n",
       "   '1de8ecb4-cfdc-47e9-8cfa-8e0f7f1b1945',\n",
       "   '--ai_endpoint',\n",
       "   'https://dc.applicationinsights.azure.com/v2/track',\n",
       "   '--subscription_id',\n",
       "   '703026c4-95fb-4a79-b674-b1648c8d0c13',\n",
       "   '--enable_metric_logger',\n",
       "   'true',\n",
       "   '--run_type',\n",
       "   'BackFill',\n",
       "   '--drift_threshold',\n",
       "   '0',\n",
       "   '--datadrift_id',\n",
       "   'b3bdb88f-67ff-4ed7-9729-27c94b5b5b7a',\n",
       "   '--datadrift_run_id',\n",
       "   'e0e86723-3e3e-4b3f-a890-472167cec769',\n",
       "   '--datadrift_name',\n",
       "   'mslearn-diabates-drift',\n",
       "   '--frequency',\n",
       "   'Week',\n",
       "   '--datadrift_configuration_type',\n",
       "   'DatasetBased',\n",
       "   '--start_date',\n",
       "   '2022-04-10',\n",
       "   '--end_date',\n",
       "   '2022-05-29',\n",
       "   '--features_whitelist',\n",
       "   'Pregnancies',\n",
       "   'Age',\n",
       "   'BMI'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'cpu-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'Experiment mslearn-diabates-drift-Monitor-Runs Environment',\n",
       "   'version': 'Autosave_2022-05-26T23:23:53Z_fad4a69b',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'scipy>=1.0.0',\n",
       "      'numpy',\n",
       "      'lightgbm<=3.1.0',\n",
       "      'pandas',\n",
       "      'pyarrow>=0.11.0',\n",
       "      'jsonpickle',\n",
       "      'psutil',\n",
       "      {'pip': ['azureml-defaults==1.41.0', 'azureml-datadrift==1.41.0']}]},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None,\n",
       "     'username': None,\n",
       "     'password': None}},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': None,\n",
       "   'enableMLflowTracking': False},\n",
       "  'spark': {'configuration': {}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 0, 'parameterServerCount': 0},\n",
       "  'mpi': {'processCountPerNode': 0},\n",
       "  'pyTorch': {'communicationBackend': None, 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'None'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=gneBWf86pTWOMbeGs1XSarMbIUG0FaMNvaaYnq2Pdlw%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A29%3A40Z&se=2022-05-27T07%3A39%3A40Z&sp=r',\n",
       "  'user_logs/std_log.txt': 'https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=%2FvgM5yswr%2FoY51BESdU3rm%2F9IThRc7PKrwiN1ZCh0E8%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A30%3A15Z&se=2022-05-27T07%3A40%3A15Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=Sbx%2FWepjH90rgB4nQljPPkdpxYKR4X58ZVfyuGi5YDM%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A30%3A16Z&se=2022-05-27T07%3A40%3A16Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=h3E8SmHXf9PoCzSr944%2BQc1FHhJkGrbvAfZoCmTjUZI%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A30%3A16Z&se=2022-05-27T07%3A40%3A16Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=mjCudHjsuTOXT65VPtCjcRpXhHvs118rgvlMM%2FV%2BprU%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A30%3A16Z&se=2022-05-27T07%3A40%3A16Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://amlworkspace6560018189.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-diabates-drift-Monitor-Runs_1653607428894/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=4YJJffgiJIqDlLLeD4ZRjADpi5PJXt2aTY3WfReLJRE%3D&skoid=20c1941d-51f7-43d0-8ae9-7d57bc58f73e&sktid=99e1e721-7184-498e-8aff-b2ad4e53c1c2&skt=2022-05-26T23%3A13%3A54Z&ske=2022-05-28T07%3A23%3A54Z&sks=b&skv=2019-07-07&st=2022-05-26T23%3A30%3A16Z&se=2022-05-27T07%3A40%3A16Z&sp=r'},\n",
       " 'submittedBy': 'LUIS FELIPE SALAZAR UCROS'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "backfill = monitor.backfill(dt.datetime.now() - dt.timedelta(weeks=6), dt.datetime.now())\n",
    "\n",
    "RunDetails(backfill).show()\n",
    "backfill.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588362e",
   "metadata": {},
   "source": [
    "## Analyze data drift\n",
    "You can use the following code to examine data drift for the points in time collected in the backfill run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c9f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date 2022-04-10\n",
      "end_date 2022-05-29\n",
      "frequency Week\n",
      "Datadrift percentage {'days_from_start': [7, 14, 21, 28, 35, 42], 'drift_percentage': [74.19152901127207, 87.23985219136877, 91.74192122865539, 94.96492628559955, 97.58354951107833, 99.23199438682525]}\n"
     ]
    }
   ],
   "source": [
    "drift_metrics = backfill.get_metrics()\n",
    "for metric in drift_metrics:\n",
    "    print(metric, drift_metrics[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694de98",
   "metadata": {},
   "source": [
    "You can also visualize the data drift metrics in Azure Machine Learning studio by following these steps:\n",
    "\n",
    "1. On the Datasets page, view the Dataset monitors tab.\n",
    "2. Click the data drift monitor you want to view.\n",
    "3. Select the date range over which you want to view data drift metrics (if the column chart does not show multiple weeks of data, wait a minute or so and click Refresh).\n",
    "4. Examine the charts in the Drift overview section at the top, which show overall drift magnitude and the drift contribution per feature.\n",
    "5. Explore the charts in the Feature detail section at the bottom, which enable you to see various measures of drift for individual features.\n",
    "Note: For help understanding the data drift metrics, see the How to monitor datasets in the Azure Machine Learning documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bd7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
